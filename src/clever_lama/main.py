"""Main application module for CleverLama."""

import asyncio
import sys
import time
from collections.abc import AsyncIterator, Awaitable, Callable
from contextlib import asynccontextmanager
from typing import Any, TypeVar

import httpx
import uvicorn
from config import settings
from constants import (
    DEFAULT_CONTENT_TYPE,
    DEFAULT_SERVER_HEADER,
    HEALTH_PROBE_DELAY,
    RESPONSE_PREFIX,
)
from endpoints import ollama_router
from fastapi import FastAPI, Request, Response
from fastapi.exceptions import RequestValidationError
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from logger import logger
from models import (
    OllamaHealthResponse,
)
from service import OpenAIService, client_holder

F = TypeVar('F', bound=Callable[..., Awaitable[Any]])

service = OpenAIService()


async def startup_event() -> None:
    """–°–æ–±—ã—Ç–∏–µ –∑–∞–ø—É—Å–∫–∞ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è."""
    try:
        client_holder.client = httpx.AsyncClient(
            base_url=settings.api_base_url,
            headers={'Authorization': f'Bearer {settings.api_key}'},
            timeout=settings.request_timeout,
        )
        logger.info(f'‚úÖ HTTP –∫–ª–∏–µ–Ω—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –¥–ª—è {settings.api_base_url}')

        await asyncio.sleep(HEALTH_PROBE_DELAY)
        await service.health_check_external_api()

    except Exception:
        logger.exception('‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è')
        await shutdown_event()
        raise


async def shutdown_event() -> None:
    """–°–æ–±—ã—Ç–∏–µ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è."""
    if client_holder.client:
        await client_holder.client.aclose()
        logger.info('‚úÖ HTTP –∫–ª–∏–µ–Ω—Ç –∑–∞–∫—Ä—ã—Ç')


@asynccontextmanager
async def lifespan(_app: FastAPI) -> AsyncIterator[None]:
    """–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∂–∏–∑–Ω–µ–Ω–Ω—ã–º —Ü–∏–∫–ª–æ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è."""
    # Startup
    logger.info('üöÄ –ó–∞–ø—É—Å–∫ CleverLama API –º–æ—Å—Ç–∞')
    await startup_event()

    yield

    # Shutdown
    logger.info('üõë –û—Å—Ç–∞–Ω–æ–≤–∫–∞ CleverLama API –º–æ—Å—Ç–∞')
    await shutdown_event()


# –°–æ–∑–¥–∞–Ω–∏–µ FastAPI –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
app = FastAPI(
    title='CleverLama',
    version='1.0.0',
    description='–ú–æ—Å—Ç –º–µ–∂–¥—É Ollama API –∏ OpenAI-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–º–∏ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞–º–∏',
    docs_url=None,  # –û—Ç–∫–ª—é—á–∞–µ–º swagger - –∫–∞–∫ y –Ω–∞—Å—Ç–æ—è—â–µ–≥–æ Ollama
    redoc_url=None,  # –û—Ç–∫–ª—é—á–∞–µ–º redoc
    lifespan=lifespan,
)

# CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=settings.allowed_origins,
    allow_credentials=True,
    allow_methods=['*'],
    allow_headers=['*'],
)


@app.exception_handler(RequestValidationError)
async def validation_exception_handler(
    request: Request, exc: RequestValidationError
) -> JSONResponse:
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –æ—à–∏–±–æ–∫ –≤–∞–ª–∏–¥–∞—Ü–∏–∏."""
    logger.error(f'‚ùå –û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –¥–ª—è {request.url.path}')
    logger.error(f'‚ùå –î–µ—Ç–∞–ª–∏ –æ—à–∏–±–æ–∫: {exc.errors()}')

    return JSONResponse(
        status_code=422,
        content={
            'detail': f' {RESPONSE_PREFIX} –û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö',
            'errors': exc.errors(),
        },
    )


@app.middleware('http')
async def add_ollama_headers(
    request: Request, call_next: Callable[[Request], Awaitable[Response]]
) -> Response:
    """–î–æ–±–∞–≤–ª—è–µ—Ç –∑–∞–≥–æ–ª–æ–≤–∫–∏ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å Ollama."""
    start_time = time.time()
    response = await call_next(request)
    process_time = time.time() - start_time

    # –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ –∫–∞–∫ y –Ω–∞—Å—Ç–æ—è—â–µ–≥–æ Ollama
    response.headers['server'] = DEFAULT_SERVER_HEADER
    response.headers['content-type'] = DEFAULT_CONTENT_TYPE
    response.headers['x-process-time'] = str(process_time)

    return response


app.include_router(ollama_router)


# –≠—Ç–æ—Ç —ç–Ω–¥–ø–æ–π–Ω—Ç –ø—Ä–æ–≤–µ—Ä—è–µ—Ç AI Assistant –ø—Ä–∏ –ø–µ—Ä–≤–æ–º —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–∏
@app.get('/')
async def health_check() -> OllamaHealthResponse:
    """Health check endpoint."""
    return OllamaHealthResponse()


if __name__ == '__main__':
    python_version = sys.version.split()[0]
    logger.info(f'üêç Python –≤–µ—Ä—Å–∏—è: {python_version}')
    logger.info(f'‚öôÔ∏è –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è: {settings.model_dump_json(indent=2)}')

    uvicorn.run(
        'main:app',
        host=settings.host,
        port=settings.port,
        log_level='info',
        access_log=True,
    )
